{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "\n",
    "result = []\n",
    "for f in glob.glob(\"*.json\"):\n",
    "    with open(f, \"rt\") as infile:\n",
    "        result.append(json.load(infile))\n",
    "\n",
    "with open(\"merged_file.json\", \"w\") as outfile:\n",
    "     json.dump(result, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "f= open(\"merged_file.json\")\n",
    "data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'run_time': 1000, 'run_id': '1000_RUNTIME', 'models_generated': 45},\n",
       " {'run_time': 1300, 'run_id': '1300_RUNTIME', 'models_generated': 65},\n",
       " {'run_time': 1500, 'run_id': '1500_RUNTIME', 'models_generated': 88},\n",
       " {'run_time': 333, 'run_id': '333_RUNTIME', 'models_generated': 6},\n",
       " {'run_time': 500, 'run_id': '500_RUNTIME', 'models_generated': 11},\n",
       " {'run_time': 700, 'run_id': '700_RUNTIME', 'models_generated': 28}]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_dict = []\n",
    "for j in range(0,6):\n",
    "    run_time = data[j]['run_time']\n",
    "    run_id = data[j]['run_id']\n",
    "    models_generated = data[j]['models_generated']\n",
    "    dict={'run_time':run_time,'run_id':run_id,'models_generated':models_generated\n",
    "              } \n",
    "    comment_dict.append(dict)\n",
    "comment_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "re=pd.DataFrame(comment_dict)\n",
    "re =re.reindex(columns=['run_time', 'run_id','models_generated'])\n",
    "re\n",
    "re.to_csv('time_models.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "\n",
    "result = []\n",
    "for f in glob.glob(\"*.json\"):\n",
    "    with open(f, \"rt\") as infile:\n",
    "        result.append(json.load(infile))\n",
    "\n",
    "with open(\"DRF.json\", \"w\") as outfile:\n",
    "     json.dump(result, outfile)\n",
    "\n",
    "f= open(\"DRF.json\")\n",
    "data_drf = json.load(f) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "f= open(\"DRF.json\")\n",
    "data_drf = json.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "DRF_dict = []\n",
    "for j in range(0,21):\n",
    "    name = data_drf[j]['model_id']['actual']['name']\n",
    "    nfolds = data_drf[j]['nfolds']['actual']\n",
    "    keep_cross_validation_models = data_drf[j]['keep_cross_validation_models']['actual']\n",
    "    keep_cross_validation_predictions = data_drf[j]['keep_cross_validation_predictions']['actual']\n",
    "    fold_assignment = data_drf[j]['fold_assignment']['actual']\n",
    "    stopping_metric = data_drf[j]['stopping_metric']['actual']\n",
    "    stopping_tolerance = data_drf[j]['stopping_tolerance']['actual']\n",
    "    seed = data_drf[j]['seed']['actual']\n",
    "    distribution = data_drf[j]['distribution']['actual']\n",
    "    \n",
    "    dict={'name':name,'nfolds':nfolds,'keep_cross_validation_models':keep_cross_validation_models,\n",
    "          'keep_cross_validation_predictions':keep_cross_validation_predictions,'fold_assignment':fold_assignment,\n",
    "          'stopping_metric':stopping_metric, 'stopping_tolerance':stopping_tolerance, 'seed':seed,\n",
    "          'distribution':distribution\n",
    "              } \n",
    "    DRF_dict.append(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "DRF_re=pd.DataFrame(DRF_dict)\n",
    "DRF_re =DRF_re.reindex(columns=['name','nfolds','keep_cross_validation_models',\n",
    "          'keep_cross_validation_predictions','fold_assignment','stopping_metric', \n",
    "          'stopping_tolerance', 'seed', 'distribution'])\n",
    "#DRF_re\n",
    "DRF_re.to_csv('DRF.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "\n",
    "result = []\n",
    "for f in glob.glob(\"*.json\"):\n",
    "    with open(f, \"rt\") as infile:\n",
    "        result.append(json.load(infile))\n",
    "\n",
    "with open(\"GLM.json\", \"w\") as outfile:\n",
    "     json.dump(result, outfile)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "f= open(\"GLM.json\")\n",
    "data_glm = json.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_dict = []\n",
    "for j in range(0,21):\n",
    "    name = data_glm[j]['model_id']['actual']['name']\n",
    "    nfolds = data_glm[j]['nfolds']['actual']\n",
    "    seed = data_glm[j]['seed']['actual']\n",
    "    solver = data_glm[j]['solver']['actual']\n",
    "    kc_val_mo = data_glm[j]['keep_cross_validation_models']['actual']\n",
    "    kc_val_pr = data_glm[j]['keep_cross_validation_predictions']['actual']\n",
    "    fold_assignment = data_glm[j]['fold_assignment']['actual']\n",
    "    lambda_search = data_glm[j]['lambda_search']['actual']\n",
    "    nlambdas = data_glm[j]['nlambdas']['actual']\n",
    "    max_iterations = data_glm[j]['max_iterations']['actual']\n",
    "    objective_epsilon = data_glm[j]['max_iterations']['actual']\n",
    "    gradient_epsilon = data_glm[j]['gradient_epsilon']['actual']\n",
    "    link = data_glm[j]['link']['actual']\n",
    "    lambda_min_ratio = data_glm[j]['lambda_min_ratio']['actual']\n",
    "    obj_reg = data_glm[j]['obj_reg']['actual']\n",
    "    \n",
    "\n",
    "    \n",
    "    dict={'name':name,'nfolds':nfolds,'seed':seed,'solver':solver,'kc_val_mo':kc_val_mo,\n",
    "          'kc_val_pr':kc_val_pr,'fold_assignment':fold_assignment,\n",
    "          'lambda_search':lambda_search,'nlambdas':nlambdas,'max_iterations':max_iterations,\n",
    "          'objective_epsilon':objective_epsilon, 'gradient_epsilon':gradient_epsilon,'link':link,\n",
    "          'lambda_min_ratio':lambda_min_ratio,'obj_reg':obj_reg\n",
    "           } \n",
    "    glm_dict.append(dict)\n",
    "    \n",
    "glm_re=pd.DataFrame(glm_dict)\n",
    "glm_re =glm_re.reindex(columns=['name','nfolds','seed','solver','kc_val_mo',\n",
    "          'kc_val_pr','fold_assignment','lambda_search',\n",
    "          'max_iterations','objective_epsilon', 'gradient_epsilon', 'link','lambda_min_ratio',\n",
    "          'obj_reg'])\n",
    "#glm_re\n",
    "glm_re.to_csv('GLM.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "\n",
    "result = []\n",
    "for f in glob.glob(\"*.json\"):\n",
    "    with open(f, \"rt\") as infile:\n",
    "        result.append(json.load(infile))\n",
    "\n",
    "with open(\"XGboost.json\", \"w\") as outfile:\n",
    "     json.dump(result, outfile)\n",
    "\n",
    "f= open(\"XGboost.json\")\n",
    "data_XGboost = json.load(f) \n",
    "#data_XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGboost_dict = []\n",
    "for j in range(1,77):\n",
    "    name = data_XGboost[j]['model_id']['actual']['name']\n",
    "    nfolds = data_XGboost[j]['nfolds']['actual']\n",
    "    \n",
    "    kc_val_mo = data_XGboost[j]['keep_cross_validation_models']['actual']\n",
    "    kc_val_pr = data_XGboost[j]['keep_cross_validation_predictions']['actual']\n",
    "    fold_assignment = data_XGboost[j]['fold_assignment']['actual']\n",
    "    stopping_rounds = data_XGboost[j]['stopping_rounds']['actual']\n",
    "    stopping_metric = data_XGboost[j]['stopping_metric']['actual']\n",
    "    max_runtime_secs = data_XGboost[j]['max_runtime_secs']['actual']\n",
    "    stopping_tolerance = data_XGboost[j]['stopping_tolerance']['actual']\n",
    "    seed = data_XGboost[j]['seed']['actual']\n",
    "    ntrees = data_XGboost[j]['ntrees']['actual']\n",
    "    max_depth = data_XGboost[j]['max_depth']['actual']\n",
    "    min_rows = data_XGboost[j]['min_rows']['actual']\n",
    "    learn_rate = data_XGboost[j]['learn_rate']['actual']\n",
    "    sample_rate = data_XGboost[j]['sample_rate']['actual']\n",
    "    col_sam_rate = data_XGboost[j]['col_sample_rate']['actual']\n",
    "    col_sam_r_per_tree = data_XGboost[j]['col_sample_rate_per_tree']['actual']\n",
    "    score_tree_interval = data_XGboost[j]['score_tree_interval']['actual']\n",
    "    \n",
    "    \n",
    "    dict={'name':name,'nfolds':nfolds,'kc_val_mo':kc_val_mo,'seed':seed,\n",
    "          'kc_val_pr':kc_val_pr,'fold_assignment':fold_assignment,\n",
    "          'stopping_rounds':stopping_rounds,'stopping_metric':stopping_metric,\n",
    "          'max_runtime_secs':max_runtime_secs,'stopping_tolerance':stopping_tolerance,\n",
    "          'ntrees':ntrees,'max_depth':max_depth,'min_rows':min_rows,\n",
    "          'learn_rate':learn_rate,'sample_rate':sample_rate,'col_sam_rate':col_sam_rate,\n",
    "          'col_sam_r_per_tree':col_sam_r_per_tree,'score_tree_interval':score_tree_interval\n",
    "           } \n",
    "    XGboost_dict.append(dict)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "XGboost_re=pd.DataFrame(XGboost_dict)\n",
    "XGboost_re =XGboost_re.reindex(columns=['name','nfolds','seed','solver','kc_val_mo',\n",
    "          'kc_val_pr','fold_assignment','ntrees','max_runtime_secs', \n",
    "          'stopping_rounds','stopping_metric','stopping_tolerance',\n",
    "          'max_depth','learn_rate','min_rows','sample_rate','col_sam_rate',\n",
    "          'col_sam_r_per_tree','score_tree_interval'])\n",
    "XGboost_re\n",
    "XGboost_re.to_csv('XGboost.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "a = pd.read_csv(\"filea.csv\")\n",
    "b = pd.read_csv(\"fileb.csv\")\n",
    "b = b.dropna(axis=1)\n",
    "merged = a.merge(b, on='title')\n",
    "merged.to_csv(\"output.csv\", index=False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
